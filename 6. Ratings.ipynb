{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"6. Ratings.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"jla-jhdbqyuy","executionInfo":{"status":"ok","timestamp":1575815777332,"user_tz":-330,"elapsed":1086,"user":{"displayName":"Rahil Memon","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBi7jh8alHX3iqwoPqZ_IO9nkoq-1mJpsBlWNd05g=s64","userId":"06800410299714917584"}},"outputId":"fa23458b-9ef4-4fe1-b598-b6964c07ae6d","colab":{"base_uri":"https://localhost:8080/","height":195}},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Review Rating , Service & Support , Information Depth . Content, User Friendly, Time to Load, Overall Rating\n","RatingColumn = \"Service & Support\"\n","\n","\n","# read data\n","reviews_df_main = pd.read_excel(\"RC.xlsx\")\n","reviews_df = pd.DataFrame()\n","reviews_df['review'] = reviews_df_main[\"Review\"]\n","reviews_df['OTA'] = reviews_df_main['OTA']\n","reviews_df['rating'] = reviews_df_main[RatingColumn]\n","\n","reviews_df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>OTA</th>\n","      <th>rating</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Hello all, I am writing a review on Makemytrip...</td>\n","      <td>MMT</td>\n","      <td>4.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Hello Friends,\\nI have booked a room in Raddis...</td>\n","      <td>MMT</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>I was trying to book an intl flight for 4 pass...</td>\n","      <td>MMT</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Unbeatable match with other trip booking apps ...</td>\n","      <td>MMT</td>\n","      <td>4.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>They cannot be reliable in matter of hotel boo...</td>\n","      <td>MMT</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                              review  OTA  rating\n","0  Hello all, I am writing a review on Makemytrip...  MMT     4.0\n","1  Hello Friends,\\nI have booked a room in Raddis...  MMT     1.0\n","2  I was trying to book an intl flight for 4 pass...  MMT     NaN\n","3  Unbeatable match with other trip booking apps ...  MMT     4.0\n","4  They cannot be reliable in matter of hotel boo...  MMT     1.0"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"lcj39tty79cc","executionInfo":{"status":"ok","timestamp":1575815783889,"user_tz":-330,"elapsed":5402,"user":{"displayName":"Rahil Memon","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBi7jh8alHX3iqwoPqZ_IO9nkoq-1mJpsBlWNd05g=s64","userId":"06800410299714917584"}},"outputId":"d54e05e7-0ea7-4212-c987-35f387a49e1d","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["!pip install xlsxwriter\n","import xlsxwriter \n","\n","workbook = xlsxwriter.Workbook('Rating.xlsx')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: xlsxwriter in /usr/local/lib/python3.6/dist-packages (1.2.6)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-TdZaVBXBezc"},"source":["#cleaning \n","\n","#removing all the \\n \n","reviews_df[\"review\"] = [x.replace(\"\\n\", \" \") for x in reviews_df[\"review\"] ]\n","\n","#removing empty values\n","reviews_df.dropna(inplace= True)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L12-I4fiBmth","executionInfo":{"status":"ok","timestamp":1575815793491,"user_tz":-330,"elapsed":11836,"user":{"displayName":"Rahil Memon","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBi7jh8alHX3iqwoPqZ_IO9nkoq-1mJpsBlWNd05g=s64","userId":"06800410299714917584"}},"outputId":"92ee39d8-9794-4a26-8222-07095dd4dc49","colab":{"base_uri":"https://localhost:8080/","height":330}},"source":["\n","# return the wordnet object value corresponding to the POS tag\n","import nltk\n","nltk.download('wordnet')\n","nltk.download('stopwords')\n","nltk.download('averaged_perceptron_tagger')\n","from nltk.corpus import wordnet\n","\n","\n","def get_wordnet_pos(pos_tag):\n","    if pos_tag.startswith('J'):\n","        return wordnet.ADJ\n","    elif pos_tag.startswith('V'):\n","        return wordnet.VERB\n","    elif pos_tag.startswith('N'):\n","        return wordnet.NOUN\n","    elif pos_tag.startswith('R'):\n","        return wordnet.ADV\n","    else:\n","        return wordnet.NOUN\n","      \n","def get_noun(pos_tag):\n","    if pos_tag.startswith('N'):\n","        return wordnet.NOUN\n","    \n","import string\n","from nltk import pos_tag\n","from nltk.corpus import stopwords\n","from nltk.tokenize import WhitespaceTokenizer\n","from nltk.stem import WordNetLemmatizer\n","\n","def clean_text(text):\n","    # lower text\n","    text = text.lower()\n","    # tokenize text and remove puncutation\n","    text = [word.strip(string.punctuation) for word in text.split(\" \")]\n","    # remove words that contain numbers\n","    text = [word for word in text if not any(c.isdigit() for c in word)]\n","    # remove stop words\n","    stop = stopwords.words('english')\n","    text = [x for x in text if x not in stop]\n","    # remove empty tokens\n","    text = [t for t in text if len(t) > 0]\n","    # pos tag text\n","    pos_tags = pos_tag(text)\n","    # lemmatize text\n","    text = [WordNetLemmatizer().lemmatize(t[0], get_wordnet_pos(t[1])) for t in pos_tags]\n","    # remove words with only one letter\n","    text = [t for t in text if len(t) > 1]\n","    # join all\n","    text = \" \".join(text)\n","    return(text)\n","\n","# clean text data\n","reviews_df[\"review\"] = reviews_df[\"review\"].apply(lambda x : str(x))\n","reviews_df[\"review_clean\"] = reviews_df['review'].apply(lambda x: clean_text(x))\n","\n","reviews_df.head()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>OTA</th>\n","      <th>rating</th>\n","      <th>review_clean</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Hello all, I am writing a review on Makemytrip...</td>\n","      <td>MMT</td>\n","      <td>4.0</td>\n","      <td>hello write review makemytrip.com reference ex...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Hello Friends, I have booked a room in Raddiso...</td>\n","      <td>MMT</td>\n","      <td>1.0</td>\n","      <td>hello friend book room raddison atrium banglor...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Unbeatable match with other trip booking apps ...</td>\n","      <td>MMT</td>\n","      <td>4.0</td>\n","      <td>unbeatable match trip book apps trust worthy a...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>They cannot be reliable in matter of hotel boo...</td>\n","      <td>MMT</td>\n","      <td>1.0</td>\n","      <td>cannot reliable matter hotel booking happen ha...</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>I had recently visited Udipur( rajsthan) with ...</td>\n","      <td>MMT</td>\n","      <td>4.0</td>\n","      <td>recently visit udipur rajsthan family vacation...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                               review  ...                                       review_clean\n","0   Hello all, I am writing a review on Makemytrip...  ...  hello write review makemytrip.com reference ex...\n","1   Hello Friends, I have booked a room in Raddiso...  ...  hello friend book room raddison atrium banglor...\n","3   Unbeatable match with other trip booking apps ...  ...  unbeatable match trip book apps trust worthy a...\n","4   They cannot be reliable in matter of hotel boo...  ...  cannot reliable matter hotel booking happen ha...\n","10  I had recently visited Udipur( rajsthan) with ...  ...  recently visit udipur rajsthan family vacation...\n","\n","[5 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"MZBM6L86CBzD","executionInfo":{"status":"ok","timestamp":1575815796752,"user_tz":-330,"elapsed":13052,"user":{"displayName":"Rahil Memon","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBi7jh8alHX3iqwoPqZ_IO9nkoq-1mJpsBlWNd05g=s64","userId":"06800410299714917584"}},"outputId":"2963f987-1399-4f37-d81c-65b1312e14a6","colab":{"base_uri":"https://localhost:8080/","height":229}},"source":["# add sentiment anaylsis columns\n","nltk.download('vader_lexicon')\n","from nltk.sentiment.vader import SentimentIntensityAnalyzer\n","\n","sid = SentimentIntensityAnalyzer()\n","reviews_df[\"sentiments\"] = reviews_df[\"review\"].apply(lambda x: sid.polarity_scores(x))\n","reviews_df = pd.concat([reviews_df.drop(['sentiments'], axis=1), reviews_df['sentiments'].apply(pd.Series)], axis=1)\n","reviews_df.head()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n","[nltk_data]   Package vader_lexicon is already up-to-date!\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>OTA</th>\n","      <th>rating</th>\n","      <th>review_clean</th>\n","      <th>neg</th>\n","      <th>neu</th>\n","      <th>pos</th>\n","      <th>compound</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Hello all, I am writing a review on Makemytrip...</td>\n","      <td>MMT</td>\n","      <td>4.0</td>\n","      <td>hello write review makemytrip.com reference ex...</td>\n","      <td>0.000</td>\n","      <td>0.785</td>\n","      <td>0.215</td>\n","      <td>0.9970</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Hello Friends, I have booked a room in Raddiso...</td>\n","      <td>MMT</td>\n","      <td>1.0</td>\n","      <td>hello friend book room raddison atrium banglor...</td>\n","      <td>0.097</td>\n","      <td>0.860</td>\n","      <td>0.043</td>\n","      <td>-0.4435</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Unbeatable match with other trip booking apps ...</td>\n","      <td>MMT</td>\n","      <td>4.0</td>\n","      <td>unbeatable match trip book apps trust worthy a...</td>\n","      <td>0.000</td>\n","      <td>0.729</td>\n","      <td>0.271</td>\n","      <td>0.9837</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>They cannot be reliable in matter of hotel boo...</td>\n","      <td>MMT</td>\n","      <td>1.0</td>\n","      <td>cannot reliable matter hotel booking happen ha...</td>\n","      <td>0.000</td>\n","      <td>0.954</td>\n","      <td>0.046</td>\n","      <td>0.4310</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>I had recently visited Udipur( rajsthan) with ...</td>\n","      <td>MMT</td>\n","      <td>4.0</td>\n","      <td>recently visit udipur rajsthan family vacation...</td>\n","      <td>0.000</td>\n","      <td>0.825</td>\n","      <td>0.175</td>\n","      <td>0.9575</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                               review  OTA  ...    pos compound\n","0   Hello all, I am writing a review on Makemytrip...  MMT  ...  0.215   0.9970\n","1   Hello Friends, I have booked a room in Raddiso...  MMT  ...  0.043  -0.4435\n","3   Unbeatable match with other trip booking apps ...  MMT  ...  0.271   0.9837\n","4   They cannot be reliable in matter of hotel boo...  MMT  ...  0.046   0.4310\n","10  I had recently visited Udipur( rajsthan) with ...  MMT  ...  0.175   0.9575\n","\n","[5 rows x 8 columns]"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"I-8x_NooCEpo"},"source":["# add number of characters column\n","reviews_df[\"nb_chars\"] = reviews_df[\"review\"].apply(lambda x: len(x))\n","\n","# add number of words column\n","reviews_df[\"nb_words\"] = reviews_df[\"review\"].apply(lambda x: len(x.split(\" \")))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sehRs_sACGo4","executionInfo":{"status":"ok","timestamp":1575815798131,"user_tz":-330,"elapsed":1353,"user":{"displayName":"Rahil Memon","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBi7jh8alHX3iqwoPqZ_IO9nkoq-1mJpsBlWNd05g=s64","userId":"06800410299714917584"}},"outputId":"f5b79759-911f-4053-e846-98915d91542f","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["\n","ratingList = []\n","for i in range(5):\n","  ratingList.append(reviews_df[reviews_df[\"rating\"]  == i+1.0 ].groupby('OTA')[\"rating\"].apply(list))\n","\n","'''for i in range(5):\n","  for j in range(5):\n","    print(len(ratingList[i][j]))\n","\n","[len(ratingList[i][\"MMT\"]) for i in range(5) ]  \n","'''\n","len(reviews_df[\"rating\"])\n","print(len(ratingList[0][0]) + len(ratingList[1][0]) + len(ratingList[2][0]) + len(ratingList[4][0]) + len(ratingList[3][0]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["250\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ikL8N4aq0Pp_","executionInfo":{"status":"ok","timestamp":1575814478295,"user_tz":-330,"elapsed":1093,"user":{"displayName":"Rahil Memon","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBi7jh8alHX3iqwoPqZ_IO9nkoq-1mJpsBlWNd05g=s64","userId":"06800410299714917584"}},"outputId":"f76df43c-ec23-445a-f5a3-9bdd366d1d35","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(ratingList[1][4])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nWjCeLvGVnmB","executionInfo":{"status":"ok","timestamp":1575813941405,"user_tz":-330,"elapsed":6561,"user":{"displayName":"Rahil Memon","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBi7jh8alHX3iqwoPqZ_IO9nkoq-1mJpsBlWNd05g=s64","userId":"06800410299714917584"}},"outputId":"5336e56c-d50b-4993-bdfb-9124dcae904b","colab":{"base_uri":"https://localhost:8080/","height":205}},"source":["!pip install xlsxwriter\n","import xlsxwriter \n","  \n","workbook = xlsxwriter.Workbook('temp.xlsx') \n","worksheet = workbook.add_worksheet() \n","\n","sum = []\n","percent = []\n","\n","\n","for i in range(5):\n","  sumval = 0\n","  for j in range(5):\n","\n","    sumval += len(ratingList[j][i]) \n","  sum.append(sumval)\n","\n","for i in range(5):\n","  percent = []\n","  for j in range(5):\n","\n","    percent.append(round(((len(ratingList[j][i]) * 100) / sum[i] ) , 1 ))\n","    worksheet.write(i, j, round(((len(ratingList[j][i]) * 100) / sum[i] ) , 1 )) \n","  worksheet.write(i, 5, sum[i])\n","  percent.append(sum[i])\n","  print(percent)\n","workbook.close()\n","  \n","\n","\n","\n","\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting xlsxwriter\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/16/da654cfbc0b05f2ad253c0f244b0c2a76c403bb774717b39c92653acb290/XlsxWriter-1.2.6-py2.py3-none-any.whl (141kB)\n","\r\u001b[K     |██▎                             | 10kB 17.8MB/s eta 0:00:01\r\u001b[K     |████▋                           | 20kB 7.1MB/s eta 0:00:01\r\u001b[K     |███████                         | 30kB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 40kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 51kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 61kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 71kB 9.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 81kB 10.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 92kB 11.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 102kB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 112kB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 122kB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 133kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 143kB 9.7MB/s \n","\u001b[?25hInstalling collected packages: xlsxwriter\n","Successfully installed xlsxwriter-1.2.6\n","[77.2, 5.5, 3.9, 7.9, 5.5, 127]\n","[56.1, 8.8, 7.1, 14.2, 13.7, 351]\n","[40.2, 5.5, 7.6, 26.3, 20.3, 433]\n","[56.0, 11.1, 11.3, 11.5, 10.0, 468]\n","[58.1, 7.1, 7.5, 15.8, 11.6, 241]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"clbBlVa1EkWy"},"source":["\n","plt.style.use('seaborn')\n","UniqueRating=['1','2','3','4','5']\n","OTA = [\"ClearTrip\", \"Goibibo\",\"MMT\", \"Redbus\", \"Yatra\"]\n","\n","fig1, axes1 = plt.subplots(1, 1)\n","fig2, axes2 = plt.subplots(1, 1)\n","fig3, axes3 = plt.subplots(1, 1)\n","fig4, axes4 = plt.subplots(1, 1)\n","fig5, axes5 = plt.subplots(1, 1)\n","\n","values = [len(ratingList[i][OTA[0]]) for i in range(5) ]  \n","axes1.set_title(OTA[0]) \n","axes1.pie(values,labels=UniqueRating, autopct='%1.1f%%')\n","\n","values = [len(ratingList[i][OTA[1]]) for i in range(5) ]  \n","axes2.set_title(OTA[1]) \n","axes2.pie(values,labels=UniqueRating, autopct='%1.1f%%')\n","\n","values = [len(ratingList[i][OTA[2]]) for i in range(5) ] \n","axes3.set_title(OTA[2])  \n","axes3.pie(values,labels=UniqueRating, autopct='%1.1f%%')\n","\n","values = [len(ratingList[i][OTA[3]]) for i in range(5) ]\n","axes4.set_title(OTA[3])   \n","axes4.pie(values,labels=UniqueRating, autopct='%1.1f%%')\n","\n","values = [len(ratingList[i][OTA[4]]) for i in range(5) ] \n","axes5.set_title(OTA[4])  \n","axes5.pie(values,labels=UniqueRating, autopct='%1.1f%%')\n","\n","plt.show()\n","#fig.savefig(\"fig.png\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CGY1pX9pSY90","executionInfo":{"status":"ok","timestamp":1574586277315,"user_tz":-330,"elapsed":17189,"user":{"displayName":"Rahil Memon","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBi7jh8alHX3iqwoPqZ_IO9nkoq-1mJpsBlWNd05g=s64","userId":"06800410299714917584"}},"outputId":"418d0947-8ca5-4dea-c7dd-f690649a25b2","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import matplotlib.backends.backend_pdf\n","pdf = matplotlib.backends.backend_pdf.PdfPages(RatingColumn+\".pdf\")\n","for fig in range(1, plt.gcf().number + 1): \n","    pdf.savefig( fig1 )\n","    pdf.savefig( fig2 )\n","    pdf.savefig( fig3 )\n","    pdf.savefig( fig4 )\n","    pdf.savefig( fig5 )\n","    \n","    \n","pdf.close()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 576x396 with 0 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"Qr-r1r0mZvpa","executionInfo":{"status":"ok","timestamp":1575817466795,"user_tz":-330,"elapsed":1293,"user":{"displayName":"Rahil Memon","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBi7jh8alHX3iqwoPqZ_IO9nkoq-1mJpsBlWNd05g=s64","userId":"06800410299714917584"}},"outputId":"bca0862a-9026-4590-87b3-52cfd1dc90a4","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print([i for i in range(7)])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[0, 1, 2, 3, 4, 5, 6]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HWsI75Fn8Wnw","executionInfo":{"status":"ok","timestamp":1575817706779,"user_tz":-330,"elapsed":92810,"user":{"displayName":"Rahil Memon","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBi7jh8alHX3iqwoPqZ_IO9nkoq-1mJpsBlWNd05g=s64","userId":"06800410299714917584"}},"outputId":"4dd02f05-fd42-4f27-a136-d019e2e75cea","colab":{"base_uri":"https://localhost:8080/","height":403}},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import string\n","from nltk import pos_tag\n","from nltk.corpus import stopwords\n","from nltk.tokenize import WhitespaceTokenizer\n","from nltk.stem import WordNetLemmatizer\n","\n","import nltk\n","nltk.download('wordnet')\n","nltk.download('stopwords')\n","nltk.download('averaged_perceptron_tagger')\n","from nltk.corpus import wordnet\n","\n","\n","# Review Rating , Service & Support , Information Depth . Content, User Friendly, Time to Load, Overall Rating\n","Cols = [\"Review Rating\" , \"Service & Support\" , \"Information Depth\" , \"Content\", \"User Friendly \", \"Time to Load\", \"Overall Rating\"]\n","\n","!pip install xlsxwriter\n","import xlsxwriter \n","\n","workbook = xlsxwriter.Workbook('Rating.xlsx')\n","\n","\n","# read data\n","reviews_df_main = pd.read_excel(\"RC.xlsx\")\n","\n","for i in range(7):\n","  RatingColumn = Cols[i]\n","  reviews_df = pd.DataFrame()\n","  reviews_df['review'] = reviews_df_main[\"Review\"]\n","  reviews_df['OTA'] = reviews_df_main['OTA']\n","  reviews_df['rating'] = reviews_df_main[RatingColumn]\n","\n","  #reviews_df.head()\n","\n","\n","  #cleaning \n","\n","  #removing all the \\n \n","  reviews_df[\"review\"] = [x.replace(\"\\n\", \" \") for x in reviews_df[\"review\"] ]\n","\n","  #removing empty values\n","  reviews_df.dropna(inplace= True)\n","\n","\n","  # return the wordnet object value corresponding to the POS tag\n","\n","\n","  def get_wordnet_pos(pos_tag):\n","      if pos_tag.startswith('J'):\n","          return wordnet.ADJ\n","      elif pos_tag.startswith('V'):\n","          return wordnet.VERB\n","      elif pos_tag.startswith('N'):\n","          return wordnet.NOUN\n","      elif pos_tag.startswith('R'):\n","          return wordnet.ADV\n","      else:\n","          return wordnet.NOUN\n","        \n","  def get_noun(pos_tag):\n","      if pos_tag.startswith('N'):\n","          return wordnet.NOUN\n","      \n","  \n","\n","  def clean_text(text):\n","      # lower text\n","      text = text.lower()\n","      # tokenize text and remove puncutation\n","      text = [word.strip(string.punctuation) for word in text.split(\" \")]\n","      # remove words that contain numbers\n","      text = [word for word in text if not any(c.isdigit() for c in word)]\n","      # remove stop words\n","      stop = stopwords.words('english')\n","      text = [x for x in text if x not in stop]\n","      # remove empty tokens\n","      text = [t for t in text if len(t) > 0]\n","      # pos tag text\n","      pos_tags = pos_tag(text)\n","      # lemmatize text\n","      text = [WordNetLemmatizer().lemmatize(t[0], get_wordnet_pos(t[1])) for t in pos_tags]\n","      # remove words with only one letter\n","      text = [t for t in text if len(t) > 1]\n","      # join all\n","      text = \" \".join(text)\n","      return(text)\n","\n","  # clean text data\n","  reviews_df[\"review\"] = reviews_df[\"review\"].apply(lambda x : str(x))\n","  reviews_df[\"review_clean\"] = reviews_df['review'].apply(lambda x: clean_text(x))\n","\n","  # add sentiment anaylsis columns\n","  nltk.download('vader_lexicon')\n","  from nltk.sentiment.vader import SentimentIntensityAnalyzer\n","\n","  sid = SentimentIntensityAnalyzer()\n","  reviews_df[\"sentiments\"] = reviews_df[\"review\"].apply(lambda x: sid.polarity_scores(x))\n","  reviews_df = pd.concat([reviews_df.drop(['sentiments'], axis=1), reviews_df['sentiments'].apply(pd.Series)], axis=1)\n","\n","\n","  ratingList = []\n","  for i in range(5):\n","    ratingList.append(reviews_df[reviews_df[\"rating\"]  == i+1.0 ].groupby('OTA')[\"rating\"].apply(list))\n","\n","\n","  worksheet = workbook.add_worksheet(RatingColumn) \n","\n","  sum = []\n","  percent = []\n","  worksheet.write(0,0, RatingColumn)\n","  OTA = [\"ClearTrip\", \"Goibibo\",\"MMT\", \"Redbus\", \"Yatra\"]\n","  for i in range(1,6):\n","    worksheet.write(i,0, OTA[i-1])\n","\n","\n","  for i in range(1,6):\n","    worksheet.write(0,i, i)\n","\n","  worksheet.write(0,6, \"Total\")\n","\n","  for i in range(5):\n","    sumval = 0\n","    for j in range(5):\n","\n","      sumval += len(ratingList[j][i]) \n","    sum.append(sumval)\n","\n","  for i in range(5):\n","    percent = []\n","    for j in range(5):\n","\n","      percent.append(len(ratingList[j][i]))\n","      worksheet.write(i+1, j+1, len(ratingList[j][i])) \n","    worksheet.write(i+1, 6, sum[i])\n","    percent.append(sum[i])\n","    #print(percent)\n","\n","workbook.close()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n","Requirement already satisfied: xlsxwriter in /usr/local/lib/python3.6/dist-packages (1.2.6)\n","[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n","[nltk_data]   Package vader_lexicon is already up-to-date!\n","[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n","[nltk_data]   Package vader_lexicon is already up-to-date!\n","[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n","[nltk_data]   Package vader_lexicon is already up-to-date!\n","[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n","[nltk_data]   Package vader_lexicon is already up-to-date!\n","[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n","[nltk_data]   Package vader_lexicon is already up-to-date!\n","[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n","[nltk_data]   Package vader_lexicon is already up-to-date!\n","[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n","[nltk_data]   Package vader_lexicon is already up-to-date!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WB0khaw5_1hY"},"source":[""],"execution_count":null,"outputs":[]}]}